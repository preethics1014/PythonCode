import pandas as pd
import json
import re
def replace_special_characters(column_name):
    # Define a regular expression pattern to match special characters
    pattern = r'[^\w\d]+'
    return re.sub(pattern, '', column_name)
 

def check_excel_columns(json_file_path, excel_file_path):
    try:
        # Load JSON lookup
        with open(json_file_path, 'r', encoding='utf-8') as f:
            lookup_data = json.load(f)
        # Load Excel file
        excel_data = pd.ExcelFile(excel_file_path)
        sheet_name = excel_data.sheet_names[0]  # Get the first sheet name
        sheet = excel_data.parse(sheet_name, header=None, skiprows=1)
        # Remove rows with null values
        sheet = sheet.dropna()
        missing_cols = [col for col in lookup_data['columns'] if col not in sheet.iloc[0]
                                                  .apply(str.strip)  
                                                  .tolist()]
        if not missing_cols:
            # Extract columns and values based on the lookup
            sheet_data = {'SheetName': sheet_name}
            for col in lookup_data['columns']:
                col_index = sheet.iloc[0].tolist().index(col)
                col_values = sheet.iloc[1:, col_index].tolist()
                sheet_data[col] = col_values
            result_df = pd.DataFrame([sheet_data])  # Create DataFrame with single row
            return result_df
        return pd.DataFrame()  # Return an empty DataFrame
    except Exception as e:
        return str(e)
def convert_dtype(dtype_name):
    # Dictionary to map data type names
    type_mapping = {
        'Int64': 'int',
        'string': 'varchar',
        'object':'int'
    }
    return type_mapping.get(dtype_name, dtype_name)  

def lookup_columns_in_current_sheet(excel_file_path, json_file_path):
    # Load JSON file
    excel_file = pd.ExcelFile(excel_file_path)
    with open(json_file_path, 'r') as json_file:
        json_data = json.load(json_file)
        lookup_columns = json_data["columns"]
    found_in_some_sheet = False
    excel_df=None
    # Iterate through all sheets
    for sheet_name in excel_file.sheet_names:
        excel_data = pd.read_excel(excel_file_path, sheet_name=sheet_name)
        excel_columns = set(excel_data.columns)
        # Check if JSON columns are missing in Excel sheet
        missing_columns = [col for col in lookup_columns if col not in excel_columns]
        if len(missing_columns) == 0:
            found_in_some_sheet = True
            excel_df = excel_data
            print(f"All JSON columns are present in sheet '{sheet_name}'.")
            excel_df = excel_data
            break  # Exit the loop since we found a sheet with all columns
    if not found_in_some_sheet:
        excel_df=validate_excel_file(excel_file_path,json_file_path)
        return excel_df
    return excel_df
def compare_excel_with_json(excel_df, json_file_path):
    # Load the JSON schema
    with open(json_file_path, 'r') as json_file:
        json_data = json.load(json_file)
    # Extract column names and their expected data types from the JSON schema
    json_columns = json_data['columns']
    json_datatypes = json_data['datatypes']
  
 
    mismatched_columns = []
   
    
    excel_df = excel_df.convert_dtypes()

    excel_df = excel_df.infer_objects()
   
    for col in excel_df.columns:
        
        
        if col in json_columns:
           
            excel_data_type = str(excel_df[col].dtype)
            json_data_type = json_datatypes[col]
            excel_data_type = convert_dtype(excel_data_type)
            json_data_type = convert_dtype(json_data_type)
            
            
            if excel_data_type != json_data_type:
                mismatched_columns.append((col, excel_data_type, json_data_type))
    print("mismatch columns",mismatched_columns)                                            
    return mismatched_columns
def validate_excel_file(excel_file_path, json_file_path):
    try:
        # Step 1: Read multiple sheets from the Excel file
        xls = pd.ExcelFile(excel_file_path)
        sheets = xls.sheet_names
    except Exception as e:
        raise Exception(f"Error reading Excel file: {e}")
    with open(json_file_path, 'r') as json_file:
        lookup_data = json.load(json_file)

 

       # Handle nested dictionaries if necessary
        if isinstance(lookup_data, dict):
            lookup_df = pd.DataFrame.from_dict(lookup_data, orient='index').T
        else:
            lookup_df = pd.DataFrame(lookup_data)

 

 

        lookup_columns = lookup_df.columns# Convert columns to a list
        lookup_columns=lookup_data["columns"]

 

 

    for sheet_name in sheets:
        try:
            df = pd.read_excel(excel_file_path, sheet_name=sheet_name, header=None, index_col=None)
            df.dropna(how="all", inplace=True)
            df.columns = df.iloc[0]
            df = df.iloc[1:]
            new_column_names = [replace_special_characters(col) for col in df.columns]
            df.columns = new_column_names
            
            matching_cols = [col for col in lookup_columns if col in df.columns]
            missing_columns = [col for col in lookup_columns if col not in df.columns]
            additional_columns = [col for col in df.columns if col not in lookup_columns]
            
            if set(lookup_columns).issubset(df.columns) or len(matching_cols) >= 2:
                if missing_columns:
                    print(f"All columns are not matched, some columns are missing in '{sheet_name}':")
                    print(missing_columns)
                    
                if additional_columns:
                    print(f"All columns are not matched, additional columns are present in '{sheet_name}':")
                    print(additional_columns)
                    return df
                
                print(f"All columns match in sheet '{sheet_name}'")
                return df
 
     
            else:
                print("hits")
                missing_columns = [col for col in lookup_columns if col not in df.columns]
                additional_columns = [col for col in df.columns if col not in lookup_columns]

                if missing_columns and df.shape[0] < df.shape[1]:
                    df_header_none = pd.read_excel(excel_file_path, sheet_name=sheet_name, header=None)
                    df_header_none.dropna(how='all', inplace=True)
                    transposed_df = df_header_none.transpose()
                    transposed_df.columns = transposed_df.iloc[0]
                    transposed_df.drop(0, inplace=True)
                    
                    transposed_columns = set(transposed_df.columns)
                    new_column_names = [replace_special_characters(col) for col in transposed_columns]
                    transposed_df.columns = new_column_names
                    print("transposed_df_collumns",transposed_df.columns)
                    print("trangaid",transposed_columns)    
                    if set(transposed_df.columns) == set(lookup_columns):
                        print(f"Columns are transposed in sheet '{sheet_name}'")
                        print("Both Lookup and transposed tables are matched.")
                        return transposed_df
                    else:
                        missing_columns = [col for col in lookup_columns if col not in transposed_df.columns]
                        additional_columns = [col for col in transposed_df.columns if col not in lookup_columns]
                        if missing_columns:
                            print(f"Columns are transposed in sheet '{sheet_name}', but still not matched.")
                            print("Missing columns in sheet:", sheet_name)
                            print(missing_columns)
                        if additional_columns:
                            print("Additional columns present in sheet:", sheet_name)
                            print(additional_columns)
                        return transposed_df

        except Exception as e:
            print(f"Error processing sheet '{sheet_name}': {e}")
            continue
excel_file_path = r'C:\Users\preethi.s\Downloads\tests.xlsx'
json_file_path = r'C:\Users\preethi.s\Documents\RDBMS\schema.json'

 
all_lookup_columns_df = lookup_columns_in_current_sheet(excel_file_path, json_file_path)


print(all_lookup_columns_df)


mismatched_columns = compare_excel_with_json(all_lookup_columns_df, json_file_path)
if not mismatched_columns:
    print("All column data types match the JSON object.")
else:
    print("*****Mismatched column data types*****:")
    for col, excel_data_type, json_data_type in mismatched_columns:
        print(f"Column '{col}' has data type '{excel_data_type}', expected '{json_data_type}'.")
